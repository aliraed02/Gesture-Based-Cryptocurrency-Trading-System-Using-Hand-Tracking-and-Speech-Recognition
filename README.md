# Gesture-Based Cryptocurrency Trading System

## Overview

Welcome to the "Gesture-Based Cryptocurrency Trading System" project! This system combines hand tracking and speech recognition to enable users to make cryptocurrency trades through gestures and voice commands. The system interprets hand gestures for trading actions (buy/sell) and uses speech recognition for user interaction.

## Project Structure

- **data**: No specific data directory is used in this project.
- **scripts**: Contains the main Python script (`predict.py`) for the gesture-based cryptocurrency trading system.

## Files

- **train.py**: Script for training the machine learning model used for hand gesture recognition.
- **predict.py**: Script for making predictions using the trained model.
- **preprocess.py**: Script for preprocessing data before training the model.
- **model.p**: The saved machine learning model (pickle file) for hand gesture recognition.
- **datafile**: Placeholder for any additional data files used in the project.

  ## Dependencies

Ensure you have the following dependencies installed before running the "Gesture-Based Cryptocurrency Trading System" project:

- **Python 3.x**: The programming language used for the project.
- **OpenCV (cv2)**: Open Source Computer Vision Library for image and video processing.
- **MediaPipe**: A library for face and hand tracking.
- **NumPy**: A library for numerical operations in Python.
- **Keras**: An open-source deep learning library.
- **SpeechRecognition**: Library for performing speech recognition.
- **pyttsx3**: Text-to-speech conversion library in Python.
- **requests**: A library for making HTTP requests in Python.

